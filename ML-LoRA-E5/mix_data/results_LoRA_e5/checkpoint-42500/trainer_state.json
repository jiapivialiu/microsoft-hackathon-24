{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 7.960292189548604,
  "eval_steps": 500,
  "global_step": 42500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.09365049634763065,
      "grad_norm": 0.3071066439151764,
      "learning_rate": 4.953174751826185e-05,
      "loss": 0.6763,
      "step": 500
    },
    {
      "epoch": 0.1873009926952613,
      "grad_norm": 0.37982454895973206,
      "learning_rate": 4.9063495036523697e-05,
      "loss": 0.6325,
      "step": 1000
    },
    {
      "epoch": 0.2809514890428919,
      "grad_norm": 0.7191796898841858,
      "learning_rate": 4.859524255478554e-05,
      "loss": 0.4472,
      "step": 1500
    },
    {
      "epoch": 0.3746019853905226,
      "grad_norm": 0.3902457058429718,
      "learning_rate": 4.812699007304739e-05,
      "loss": 0.2864,
      "step": 2000
    },
    {
      "epoch": 0.4682524817381532,
      "grad_norm": 0.4880572259426117,
      "learning_rate": 4.765873759130924e-05,
      "loss": 0.2165,
      "step": 2500
    },
    {
      "epoch": 0.5619029780857838,
      "grad_norm": 0.8197706341743469,
      "learning_rate": 4.719048510957108e-05,
      "loss": 0.1803,
      "step": 3000
    },
    {
      "epoch": 0.6555534744334145,
      "grad_norm": 0.6611018180847168,
      "learning_rate": 4.672223262783293e-05,
      "loss": 0.1606,
      "step": 3500
    },
    {
      "epoch": 0.7492039707810452,
      "grad_norm": 0.6455024480819702,
      "learning_rate": 4.625398014609478e-05,
      "loss": 0.1404,
      "step": 4000
    },
    {
      "epoch": 0.8428544671286757,
      "grad_norm": 0.6976544260978699,
      "learning_rate": 4.578572766435662e-05,
      "loss": 0.1362,
      "step": 4500
    },
    {
      "epoch": 0.9365049634763064,
      "grad_norm": 0.818458616733551,
      "learning_rate": 4.5317475182618466e-05,
      "loss": 0.1268,
      "step": 5000
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.9423112942498595,
      "eval_loss": 0.1473541557788849,
      "eval_runtime": 157.367,
      "eval_samples_per_second": 67.854,
      "eval_steps_per_second": 67.854,
      "step": 5339
    },
    {
      "epoch": 1.030155459823937,
      "grad_norm": 0.060911111533641815,
      "learning_rate": 4.484922270088032e-05,
      "loss": 0.1097,
      "step": 5500
    },
    {
      "epoch": 1.1238059561715676,
      "grad_norm": 0.03740669786930084,
      "learning_rate": 4.438097021914217e-05,
      "loss": 0.1064,
      "step": 6000
    },
    {
      "epoch": 1.2174564525191984,
      "grad_norm": 0.030735835433006287,
      "learning_rate": 4.391271773740401e-05,
      "loss": 0.1255,
      "step": 6500
    },
    {
      "epoch": 1.311106948866829,
      "grad_norm": 0.031935691833496094,
      "learning_rate": 4.3444465255665855e-05,
      "loss": 0.1161,
      "step": 7000
    },
    {
      "epoch": 1.4047574452144596,
      "grad_norm": 0.024226868525147438,
      "learning_rate": 4.2976212773927705e-05,
      "loss": 0.1074,
      "step": 7500
    },
    {
      "epoch": 1.4984079415620903,
      "grad_norm": 0.03014327399432659,
      "learning_rate": 4.2507960292189556e-05,
      "loss": 0.107,
      "step": 8000
    },
    {
      "epoch": 1.592058437909721,
      "grad_norm": 0.022887084633111954,
      "learning_rate": 4.203970781045139e-05,
      "loss": 0.0922,
      "step": 8500
    },
    {
      "epoch": 1.6857089342573515,
      "grad_norm": 0.021318724378943443,
      "learning_rate": 4.157145532871324e-05,
      "loss": 0.0981,
      "step": 9000
    },
    {
      "epoch": 1.7793594306049823,
      "grad_norm": 0.022053934633731842,
      "learning_rate": 4.1103202846975093e-05,
      "loss": 0.1017,
      "step": 9500
    },
    {
      "epoch": 1.8730099269526128,
      "grad_norm": 0.0489346906542778,
      "learning_rate": 4.063495036523694e-05,
      "loss": 0.0968,
      "step": 10000
    },
    {
      "epoch": 1.9666604233002434,
      "grad_norm": 0.08396947383880615,
      "learning_rate": 4.016669788349878e-05,
      "loss": 0.1016,
      "step": 10500
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.9435287507023787,
      "eval_loss": 0.16143204271793365,
      "eval_runtime": 155.7757,
      "eval_samples_per_second": 68.547,
      "eval_steps_per_second": 68.547,
      "step": 10678
    },
    {
      "epoch": 2.060310919647874,
      "grad_norm": 0.036874108016490936,
      "learning_rate": 3.969844540176063e-05,
      "loss": 0.0967,
      "step": 11000
    },
    {
      "epoch": 2.153961415995505,
      "grad_norm": 0.01991899497807026,
      "learning_rate": 3.923019292002248e-05,
      "loss": 0.0868,
      "step": 11500
    },
    {
      "epoch": 2.2476119123431353,
      "grad_norm": 0.02257688343524933,
      "learning_rate": 3.8761940438284325e-05,
      "loss": 0.0846,
      "step": 12000
    },
    {
      "epoch": 2.341262408690766,
      "grad_norm": 0.02616378664970398,
      "learning_rate": 3.829368795654617e-05,
      "loss": 0.0868,
      "step": 12500
    },
    {
      "epoch": 2.434912905038397,
      "grad_norm": 0.0155921196565032,
      "learning_rate": 3.782543547480802e-05,
      "loss": 0.0913,
      "step": 13000
    },
    {
      "epoch": 2.528563401386027,
      "grad_norm": 9.012669563293457,
      "learning_rate": 3.735718299306987e-05,
      "loss": 0.0941,
      "step": 13500
    },
    {
      "epoch": 2.622213897733658,
      "grad_norm": 0.01785588264465332,
      "learning_rate": 3.688893051133171e-05,
      "loss": 0.0845,
      "step": 14000
    },
    {
      "epoch": 2.7158643940812888,
      "grad_norm": 0.013198792934417725,
      "learning_rate": 3.642067802959356e-05,
      "loss": 0.0919,
      "step": 14500
    },
    {
      "epoch": 2.809514890428919,
      "grad_norm": 0.12346431612968445,
      "learning_rate": 3.595242554785541e-05,
      "loss": 0.0954,
      "step": 15000
    },
    {
      "epoch": 2.90316538677655,
      "grad_norm": 0.1226511150598526,
      "learning_rate": 3.548417306611725e-05,
      "loss": 0.0828,
      "step": 15500
    },
    {
      "epoch": 2.9968158831241807,
      "grad_norm": 0.013754374347627163,
      "learning_rate": 3.5015920584379095e-05,
      "loss": 0.0787,
      "step": 16000
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.9574826746581757,
      "eval_loss": 0.1157802864909172,
      "eval_runtime": 156.11,
      "eval_samples_per_second": 68.4,
      "eval_steps_per_second": 68.4,
      "step": 16017
    },
    {
      "epoch": 3.090466379471811,
      "grad_norm": 0.2680489122867584,
      "learning_rate": 3.4547668102640946e-05,
      "loss": 0.0744,
      "step": 16500
    },
    {
      "epoch": 3.184116875819442,
      "grad_norm": 0.015218674205243587,
      "learning_rate": 3.4079415620902796e-05,
      "loss": 0.0785,
      "step": 17000
    },
    {
      "epoch": 3.2777673721670726,
      "grad_norm": 8.749617576599121,
      "learning_rate": 3.361116313916463e-05,
      "loss": 0.0817,
      "step": 17500
    },
    {
      "epoch": 3.371417868514703,
      "grad_norm": 0.03232771158218384,
      "learning_rate": 3.3142910657426484e-05,
      "loss": 0.0874,
      "step": 18000
    },
    {
      "epoch": 3.4650683648623337,
      "grad_norm": 0.00883200392127037,
      "learning_rate": 3.2674658175688334e-05,
      "loss": 0.0936,
      "step": 18500
    },
    {
      "epoch": 3.5587188612099645,
      "grad_norm": 0.021510936319828033,
      "learning_rate": 3.2206405693950184e-05,
      "loss": 0.0762,
      "step": 19000
    },
    {
      "epoch": 3.6523693575575953,
      "grad_norm": 0.014513046480715275,
      "learning_rate": 3.173815321221202e-05,
      "loss": 0.0702,
      "step": 19500
    },
    {
      "epoch": 3.7460198539052256,
      "grad_norm": 0.042271703481674194,
      "learning_rate": 3.126990073047387e-05,
      "loss": 0.0641,
      "step": 20000
    },
    {
      "epoch": 3.8396703502528564,
      "grad_norm": 0.04738596826791763,
      "learning_rate": 3.080164824873572e-05,
      "loss": 0.0762,
      "step": 20500
    },
    {
      "epoch": 3.9333208466004868,
      "grad_norm": 0.013736987486481667,
      "learning_rate": 3.033339576699757e-05,
      "loss": 0.0753,
      "step": 21000
    },
    {
      "epoch": 4.0,
      "eval_accuracy": 0.948773178497846,
      "eval_loss": 0.1580447256565094,
      "eval_runtime": 155.9697,
      "eval_samples_per_second": 68.462,
      "eval_steps_per_second": 68.462,
      "step": 21356
    },
    {
      "epoch": 4.0269713429481175,
      "grad_norm": 0.018919620662927628,
      "learning_rate": 2.9865143285259413e-05,
      "loss": 0.0703,
      "step": 21500
    },
    {
      "epoch": 4.120621839295748,
      "grad_norm": 2.335578203201294,
      "learning_rate": 2.939689080352126e-05,
      "loss": 0.0765,
      "step": 22000
    },
    {
      "epoch": 4.214272335643379,
      "grad_norm": 0.05183360353112221,
      "learning_rate": 2.8928638321783107e-05,
      "loss": 0.0766,
      "step": 22500
    },
    {
      "epoch": 4.30792283199101,
      "grad_norm": 0.01543971337378025,
      "learning_rate": 2.8460385840044958e-05,
      "loss": 0.0705,
      "step": 23000
    },
    {
      "epoch": 4.40157332833864,
      "grad_norm": 0.011527358554303646,
      "learning_rate": 2.7992133358306798e-05,
      "loss": 0.0776,
      "step": 23500
    },
    {
      "epoch": 4.495223824686271,
      "grad_norm": 0.011773177422583103,
      "learning_rate": 2.752388087656865e-05,
      "loss": 0.0784,
      "step": 24000
    },
    {
      "epoch": 4.588874321033901,
      "grad_norm": 0.02226484753191471,
      "learning_rate": 2.7055628394830496e-05,
      "loss": 0.0611,
      "step": 24500
    },
    {
      "epoch": 4.682524817381532,
      "grad_norm": 0.03160099312663078,
      "learning_rate": 2.658737591309234e-05,
      "loss": 0.0695,
      "step": 25000
    },
    {
      "epoch": 4.776175313729163,
      "grad_norm": 0.019753077998757362,
      "learning_rate": 2.6119123431354186e-05,
      "loss": 0.073,
      "step": 25500
    },
    {
      "epoch": 4.869825810076794,
      "grad_norm": 5.5183634757995605,
      "learning_rate": 2.5650870949616033e-05,
      "loss": 0.077,
      "step": 26000
    },
    {
      "epoch": 4.963476306424424,
      "grad_norm": 0.058382827788591385,
      "learning_rate": 2.5182618467877884e-05,
      "loss": 0.0692,
      "step": 26500
    },
    {
      "epoch": 5.0,
      "eval_accuracy": 0.9624461509646001,
      "eval_loss": 0.10883355140686035,
      "eval_runtime": 155.455,
      "eval_samples_per_second": 68.689,
      "eval_steps_per_second": 68.689,
      "step": 26695
    },
    {
      "epoch": 5.057126802772054,
      "grad_norm": 0.00747780641540885,
      "learning_rate": 2.4714365986139728e-05,
      "loss": 0.0703,
      "step": 27000
    },
    {
      "epoch": 5.150777299119685,
      "grad_norm": 0.0076859816908836365,
      "learning_rate": 2.4246113504401575e-05,
      "loss": 0.0638,
      "step": 27500
    },
    {
      "epoch": 5.244427795467316,
      "grad_norm": 0.010332793928682804,
      "learning_rate": 2.377786102266342e-05,
      "loss": 0.0686,
      "step": 28000
    },
    {
      "epoch": 5.338078291814947,
      "grad_norm": 0.007072513923048973,
      "learning_rate": 2.330960854092527e-05,
      "loss": 0.0695,
      "step": 28500
    },
    {
      "epoch": 5.4317287881625775,
      "grad_norm": 0.00548475282266736,
      "learning_rate": 2.2841356059187112e-05,
      "loss": 0.0615,
      "step": 29000
    },
    {
      "epoch": 5.525379284510208,
      "grad_norm": 0.0056111449375748634,
      "learning_rate": 2.2373103577448963e-05,
      "loss": 0.0692,
      "step": 29500
    },
    {
      "epoch": 5.619029780857838,
      "grad_norm": 0.007211549673229456,
      "learning_rate": 2.1904851095710807e-05,
      "loss": 0.0692,
      "step": 30000
    },
    {
      "epoch": 5.712680277205469,
      "grad_norm": 0.011437938548624516,
      "learning_rate": 2.1436598613972657e-05,
      "loss": 0.0736,
      "step": 30500
    },
    {
      "epoch": 5.8063307735531,
      "grad_norm": 0.014172258786857128,
      "learning_rate": 2.09683461322345e-05,
      "loss": 0.0615,
      "step": 31000
    },
    {
      "epoch": 5.899981269900731,
      "grad_norm": 0.009687685407698154,
      "learning_rate": 2.0500093650496348e-05,
      "loss": 0.075,
      "step": 31500
    },
    {
      "epoch": 5.993631766248361,
      "grad_norm": 0.0481402762234211,
      "learning_rate": 2.0031841168758195e-05,
      "loss": 0.0766,
      "step": 32000
    },
    {
      "epoch": 6.0,
      "eval_accuracy": 0.9598239370668664,
      "eval_loss": 0.1179671585559845,
      "eval_runtime": 157.0963,
      "eval_samples_per_second": 67.971,
      "eval_steps_per_second": 67.971,
      "step": 32034
    },
    {
      "epoch": 6.087282262595992,
      "grad_norm": 0.18636193871498108,
      "learning_rate": 1.9563588687020042e-05,
      "loss": 0.0667,
      "step": 32500
    },
    {
      "epoch": 6.180932758943622,
      "grad_norm": 0.006623368244618177,
      "learning_rate": 1.909533620528189e-05,
      "loss": 0.0621,
      "step": 33000
    },
    {
      "epoch": 6.274583255291253,
      "grad_norm": 0.012304256670176983,
      "learning_rate": 1.8627083723543736e-05,
      "loss": 0.0681,
      "step": 33500
    },
    {
      "epoch": 6.368233751638884,
      "grad_norm": 0.005442144349217415,
      "learning_rate": 1.8158831241805583e-05,
      "loss": 0.0647,
      "step": 34000
    },
    {
      "epoch": 6.461884247986514,
      "grad_norm": 0.025884799659252167,
      "learning_rate": 1.769057876006743e-05,
      "loss": 0.0696,
      "step": 34500
    },
    {
      "epoch": 6.555534744334145,
      "grad_norm": 0.005395598243921995,
      "learning_rate": 1.7222326278329277e-05,
      "loss": 0.0644,
      "step": 35000
    },
    {
      "epoch": 6.649185240681776,
      "grad_norm": 0.004457569215446711,
      "learning_rate": 1.675407379659112e-05,
      "loss": 0.0683,
      "step": 35500
    },
    {
      "epoch": 6.742835737029406,
      "grad_norm": 1.020597219467163,
      "learning_rate": 1.6285821314852968e-05,
      "loss": 0.0691,
      "step": 36000
    },
    {
      "epoch": 6.836486233377037,
      "grad_norm": 0.004889816511422396,
      "learning_rate": 1.5817568833114815e-05,
      "loss": 0.0682,
      "step": 36500
    },
    {
      "epoch": 6.930136729724667,
      "grad_norm": 0.0051666609942913055,
      "learning_rate": 1.5349316351376662e-05,
      "loss": 0.0585,
      "step": 37000
    },
    {
      "epoch": 7.0,
      "eval_accuracy": 0.9535493538115752,
      "eval_loss": 0.14870533347129822,
      "eval_runtime": 158.7725,
      "eval_samples_per_second": 67.253,
      "eval_steps_per_second": 67.253,
      "step": 37373
    },
    {
      "epoch": 7.023787226072298,
      "grad_norm": 6.469193935394287,
      "learning_rate": 1.488106386963851e-05,
      "loss": 0.0578,
      "step": 37500
    },
    {
      "epoch": 7.117437722419929,
      "grad_norm": 0.01577635109424591,
      "learning_rate": 1.4412811387900358e-05,
      "loss": 0.0709,
      "step": 38000
    },
    {
      "epoch": 7.21108821876756,
      "grad_norm": 0.009363432414829731,
      "learning_rate": 1.3944558906162204e-05,
      "loss": 0.0729,
      "step": 38500
    },
    {
      "epoch": 7.304738715115191,
      "grad_norm": 0.005300222430378199,
      "learning_rate": 1.347630642442405e-05,
      "loss": 0.067,
      "step": 39000
    },
    {
      "epoch": 7.3983892114628205,
      "grad_norm": 0.02641986683011055,
      "learning_rate": 1.3008053942685896e-05,
      "loss": 0.0686,
      "step": 39500
    },
    {
      "epoch": 7.492039707810451,
      "grad_norm": 0.021990256384015083,
      "learning_rate": 1.2539801460947745e-05,
      "loss": 0.0635,
      "step": 40000
    },
    {
      "epoch": 7.585690204158082,
      "grad_norm": 0.01857485994696617,
      "learning_rate": 1.207154897920959e-05,
      "loss": 0.0496,
      "step": 40500
    },
    {
      "epoch": 7.679340700505713,
      "grad_norm": 0.00465850206092,
      "learning_rate": 1.1603296497471437e-05,
      "loss": 0.0639,
      "step": 41000
    },
    {
      "epoch": 7.772991196853344,
      "grad_norm": 0.00758729362860322,
      "learning_rate": 1.1135044015733284e-05,
      "loss": 0.0657,
      "step": 41500
    },
    {
      "epoch": 7.8666416932009735,
      "grad_norm": 0.4073605537414551,
      "learning_rate": 1.0666791533995131e-05,
      "loss": 0.0648,
      "step": 42000
    },
    {
      "epoch": 7.960292189548604,
      "grad_norm": 0.005535608157515526,
      "learning_rate": 1.0198539052256978e-05,
      "loss": 0.0649,
      "step": 42500
    }
  ],
  "logging_steps": 500,
  "max_steps": 53390,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.5926774058178704e+16,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}

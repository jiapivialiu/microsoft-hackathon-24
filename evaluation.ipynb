{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of our final model on benchmark RAID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import packages\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"torch.utils._pytree._register_pytree_node is deprecated\")\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from peft import PeftModel, PeftConfig\n",
    "from datasets import load_dataset\n",
    "# import RAID\n",
    "import json\n",
    "from raid import run_detection, run_evaluation\n",
    "from raid.utils import load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# disable parallel computing\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "# suppress warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\".*resume_download.*\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the working directories\n",
    "current_dir = os.getcwd()\n",
    "model_dir = os.path.join(current_dir, \"ML-LoRA-E5/twitter_raid_data/raid_twitter_LoRA_e5\")\n",
    "data_dir = os.path.join(current_dir, \"data/\")\n",
    "eval_dir = os.path.join(data_dir, \"evaluation/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import helper functions\n",
    "model_helpers_path = os.path.join(current_dir, \"src/model_helpers.py\")\n",
    "%run $model_helpers_path\n",
    "\n",
    "data_helpers_path = os.path.join(current_dir, \"src/data_helpers.py\")\n",
    "%run $data_helpers_path\n",
    "\n",
    "evaluate_helpers_path = os.path.join(current_dir, \"src/evaluate_helpers.py\")\n",
    "%run $evaluate_helpers_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the fine-tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the directory of the latest model checkpoints\n",
    "lora_checkpoints_dir = os.path.join(model_dir, \"checkpoint-29745\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at intfloat/e5-small and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load the tokenizer and base model (e.g., BERT, GPT-2)\n",
    "base_model_name = \"intfloat/e5-small\"  # Change to the base model you used\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_name)\n",
    "base_model = AutoModelForSequenceClassification.from_pretrained(base_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load the LoRA fine-tuned model (with the latest checkpoints)\n",
    "our_model = PeftModel.from_pretrained(base_model, lora_checkpoints_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Evaluate our detector on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the RAID test data\n",
    "test_df = load_data(split=\"test\")\n",
    "#test_df = read_csv(os.path.join(eval_dir, \"test_raid_set.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Dataset({\n",
      "    features: ['id', 'generation'],\n",
      "    num_rows: 672000\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "test_ds = Dataset.from_pandas(test_df)\n",
    "print(isinstance(test_ds, Dataset))\n",
    "print(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     id  \\\n",
      "0  c39744bc-bfb4-49b4-8508-4149547be2a5   \n",
      "1  9c5acac0-def5-44d5-a154-9863a6eab11b   \n",
      "2  7b8b7930-8aee-4be5-8208-ff41e742d669   \n",
      "\n",
      "                                          generation  \n",
      "0  Ingredients:\\n- 1 loaf of corn bread, crumbled...  \n",
      "1  Feker Libi, is a song  by Ehud Banai  and Yeho...  \n",
      "2  Rebecca L. Gottesman (born 1962) is an America...  \n",
      "(68, 2)\n"
     ]
    }
   ],
   "source": [
    "# Generate a random subset for testing\n",
    "test_subset = test_ds.train_test_split(test_size=0.0001, shuffle=True, seed=12)['test']\n",
    "test_subset_df = Dataset.to_pandas(test_subset)\n",
    "print(test_subset_df.head(3))\n",
    "print(test_subset_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define my detector function for evaluation on RAID test set\n",
    "def my_detector(texts: list[str], model = our_model) -> list[float]:\n",
    "    predicted_probs = inference_model(model, texts)\n",
    "    return predicted_probs.predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec45362b860749d89c58ca91ef1b1ff4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing data:   0%|          | 0/68 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "# Run your detector on the dataset\n",
    "predictions = run_detection(my_detector, test_subset_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9807470440864563, 0.9815977811813354]\n"
     ]
    }
   ],
   "source": [
    "pred_probs = [item['score']['Predicted_Probs(1)'] for item in predictions]\n",
    "print(pred_probs[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the predictions\n",
    "with open(os.path.join(data_dir, \"predictions.json\"), 'w') as f:\n",
    "    json.dump(predictions, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 0, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "# Get predicted labels\n",
    "pred_label = get_predicted_labels(pred_probs, 0.95)\n",
    "print(pred_label[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Evaluate our detector on an extra set with new domain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Load the extra set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import zipfile\n",
    "#\n",
    "## Path to the zip file\n",
    "#zip_file_path = os.path.join(eval_dir, \"RAID_extra_noadv_df.csv.zip\")\n",
    "## Directory to extract to (can be the same as zip_file_path or another directory)\n",
    "#\n",
    "## Create the directory if it doesn't exist\n",
    "#os.makedirs(eval_dir, exist_ok=True)\n",
    "#\n",
    "## Open the zip file\n",
    "#with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "#    # Extract all contents into the specified directory\n",
    "#    zip_ref.extractall(eval_dir)\n",
    "#\n",
    "#print(f\"Extracted all files successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['id', 'adv_source_id', 'source_id', 'model', 'decoding', 'repetition_penalty', 'attack', 'domain', 'title', 'prompt', 'generation'],\n",
      "    num_rows: 2039100\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Load validation set without adversarial attacks\n",
    "extra_set = load_dataset(\"csv\", data_files=os.path.join(eval_dir, \"RAID_extra_adv_df.csv\"), split = 'all')\n",
    "print(extra_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the adversarial-attack set for training\n",
    "processed_set = process_data(extra_set, \"generation\", \"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProcessedData with 2039100 rows\n",
      "True\n",
      "Count of human-written entries: 58260\n",
      "Count of machine-generated entries: 1980840\n"
     ]
    }
   ],
   "source": [
    "# Print summary of the processed set\n",
    "print(processed_set)\n",
    "print(is_processed_data(processed_set))\n",
    "label_counter(processed_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a random sample\n",
    "excluded_data, processed_subset = train_test_split_unequal_class(processed_set, test_size = 0.001, seed = 620)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProcessedData with 2039100 rows\n",
      "ProcessedData with 2040 rows\n"
     ]
    }
   ],
   "source": [
    "print(processed_set)\n",
    "\n",
    "# Remove columns other than text and labels\n",
    "reduced_processed_subset = process_data(processed_subset, \"text\", \"labels\", reduced=True)\n",
    "print(reduced_processed_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Evaluate our detector on the extra set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58895919ddf8433aa7e0fc34f6057eea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing data:   0%|          | 0/2040 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 100 entries...\n",
      "Processed 200 entries...\n",
      "Processed 300 entries...\n",
      "Processed 400 entries...\n",
      "Processed 500 entries...\n",
      "Processed 600 entries...\n",
      "Processed 700 entries...\n",
      "Processed 800 entries...\n",
      "Processed 900 entries...\n",
      "Processed 1000 entries...\n",
      "Processed 1100 entries...\n",
      "Processed 1200 entries...\n",
      "Processed 1300 entries...\n",
      "Processed 1400 entries...\n",
      "Processed 1500 entries...\n",
      "Processed 1600 entries...\n",
      "Processed 1700 entries...\n",
      "Processed 1800 entries...\n",
      "Processed 1900 entries...\n",
      "Processed 2000 entries...\n"
     ]
    }
   ],
   "source": [
    "predicted_probs = inference_model(our_model, reduced_processed_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined DataFrame saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# Save predictions to a CSV file\n",
    "res_csv_path = os.path.join(eval_dir, 'pred_extra_adv_subset.csv')\n",
    "save_inference_to_csv(predicted_probs, reduced_processed_subset, res_csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "{'Accuracy': 0.956, 'F1 score': 0.955, 'FPR': 0.044}\n"
     ]
    }
   ],
   "source": [
    "print(isinstance(predicted_probs, PredictionResults))\n",
    "\n",
    "# Compute metrics\n",
    "predicted_label = get_predicted_labels(predicted_probs, 0.6)\n",
    "res = evaluate_model(predicted_label, reduced_processed_subset)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  labels  \\\n",
      "0  import cmath\\ndef phase_angle(complex_number):...       1   \n",
      "\n",
      "   Predicted_Probs(1)  \n",
      "0            0.718956  \n"
     ]
    }
   ],
   "source": [
    "# Read the results as pandas.DataFrame\n",
    "res_dataframe = read_inference_as_DataFrame(res_csv_path)\n",
    "print(res_dataframe.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': ['import cmath\\ndef phase_angle(complex_number):\\n    # Convert complex number to Python complex type\\n    num = complex(complex_number)\\n    \\n    # Calculate the phase angle of the complex number\\n    angle = cmath.phase(num)\\n    \\n    # Return the phase angle of complex number\\n    return angle'], 'labels': [1], 'Predicted_Probs(1)': [0.718956]}\n"
     ]
    }
   ],
   "source": [
    "# Read the results as datasets.Dataset\n",
    "res_dataset = read_inference_as_Dataset(res_csv_path)\n",
    "print(res_dataset[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
